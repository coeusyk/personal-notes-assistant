# Copy this file to .env and fill in your values.

# --- Required Settings ---
# Absolute path to your Obsidian vault.
# Example for Windows: C:/Users/YourUser/Documents/ObsidianVault
# Example for macOS/Linux: /Users/YourUser/Documents/ObsidianVault
OBSIDIAN_VAULT_PATH=

# --- LLM Provider Settings ---
# Set the provider to either 'ollama' or 'openai'. Defaults to 'ollama' if not set.
LLM_PROVIDER=ollama

# --- Ollama Settings (used if LLM_PROVIDER is 'ollama') ---
# The base URL for your local Ollama server. The /v1 endpoint will be added automatically.
OLLAMA_URL=http://localhost:11434
# The model to use with Ollama (e.g., mistral:7b-instruct, llama3).
# This is required if you use ollama.
LLM_MODEL=mistral:7b-instruct

# --- OpenAI Settings (used if LLM_PROVIDER is 'openai') ---
# Your API key from OpenAI. This is required if you use openai.
OPENAI_API_KEY=your-openai-api-key-here
# The model to use with OpenAI (e.g., gpt-4, gpt-3.5-turbo).
# If you use openai, uncomment the line below and set your desired model.
# LLM_MODEL=gpt-3.5-turbo

# --- Milvus Settings (Optional) ---
# Host and port for your Milvus instance. Defaults to localhost:19530.
MILVUS_HOST=localhost
MILVUS_PORT=19530